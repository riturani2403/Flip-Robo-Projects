{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape the details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls \n",
    "naukri_urls = []\n",
    "urls = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for url in urls[0:10]:\n",
    "    naukri_urls.append(url.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-data-analytics-data-scientist-intern-work-from-home-talkvalley-llc-kolkata-bangalore-bengaluru-delhi-ncr-0-to-5-years-050621000128?src=jobsearchDesk&sid=16241905837731397&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-lead-predictive-analytics-ave-promagne-chennai-7-to-10-years-140621900598?src=jobsearchDesk&sid=16241905837731397&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-redbus-in-ibibo-group-private-limited-bangalore-bengaluru-5-to-8-years-090621001584?src=jobsearchDesk&sid=16241905837731397&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-immediate-opening-senior-data-scientist-redbus-in-ibibo-group-private-limited-bangalore-bengaluru-5-to-8-years-140621005528?src=jobsearchDesk&sid=16241905837731397&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-fractal-analytics-ltd-mumbai-gurgaon-gurugram-bangalore-bengaluru-5-to-9-years-140621500966?src=jobsearchDesk&sid=16241905837731397&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-fico-bangalore-bengaluru-6-to-11-years-090621500701?src=jobsearchDesk&sid=16241905837731397&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-fractal-analytics-pvt-ltd-gurgaon-gurugram-bangalore-bengaluru-mumbai-all-areas-10-to-15-years-110621003012?src=jobsearchDesk&sid=16241905837731397&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-science-associate-data-scientist-jet2-travel-technologies-pvt-ltd-pune-0-to-2-years-110621008316?src=jobsearchDesk&sid=16241905837731397&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-chaayos-is-looking-for-data-scientist-chaayos-sunshine-teahouse-pvt-ltd-new-delhi-0-to-5-years-070621000819?src=jobsearchDesk&sid=16241905837731397&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-associate-data-scientist-algoanalytics-private-ltd-pune-0-to-1-years-160621002621?src=jobsearchDesk&sid=16241905837731397&xp=10&px=1']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naukri_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining varaibles\n",
    "\n",
    "time.sleep(4)\n",
    "# creating empty lists for scraping data\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "job_title=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data from each url\n",
    "for url in naukri_urls[:10]:\n",
    "    driver.get(url)    # Saving url                                                     \n",
    "    \n",
    "    # fetchinf job_title\n",
    "    try:\n",
    "        job = driver.find_element_by_xpath('//h1[@class=\"jd-header-title\"]')  \n",
    "        job_title.append(job.text)\n",
    "    except NoSuchElementException:\n",
    "        job_title.append('-')\n",
    "        \n",
    "    #fetching job_location   \n",
    "    try:\n",
    "        location = driver.find_element_by_xpath('//div[@class=\"loc\"]')  \n",
    "        job_location.append(location.text)\n",
    "    except NoSuchElementException:\n",
    "        job_location.append('-')\n",
    "        \n",
    "     # fetching company name\n",
    "    try:\n",
    "        companies = driver.find_element_by_xpath('//div[@class=\"jd-header-comp-name\"]')  \n",
    "        company_name.append(companies.text)\n",
    "    except NoSuchElementException:\n",
    "        company_name.append('-')\n",
    "        \n",
    "     # experience\n",
    "    try:\n",
    "        experience = driver.find_element_by_xpath('//div[@class=\"exp\"]')  \n",
    "        experience_required.append(experience.text)\n",
    "    except NoSuchElementException:\n",
    "        experience_required.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_location))\n",
    "print(len(job_title))\n",
    "print(len(company_name))\n",
    "print(len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 - 5 years</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 - 10 years</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Senior Data Scientist / Lead (Predictive Analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 - 9 years</td>\n",
       "      <td>Fractal Analytics3.9(95 Reviews)</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6 - 11 years</td>\n",
       "      <td>FICO3.8(59 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10 - 15 years</td>\n",
       "      <td>Fractal Analytics3.9(95 Reviews)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0 - 2 years</td>\n",
       "      <td>Jet2 Travel Technologies Pvt. Ltd.</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science- Associate Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0 - 5 years</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)3.9(159 R...</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0 - 1 years</td>\n",
       "      <td>AlgoAnalytics Private Ltd.4.0(2 Reviews)</td>\n",
       "      <td>Pune( Baner )</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                                       company_name  \\\n",
       "0         0 - 5 years                                     TalkValley LLC   \n",
       "1        7 - 10 years                                       AVE-Promagne   \n",
       "2                   -                                                  -   \n",
       "3                   -                                                  -   \n",
       "4         5 - 9 years                   Fractal Analytics3.9(95 Reviews)   \n",
       "5        6 - 11 years                                FICO3.8(59 Reviews)   \n",
       "6       10 - 15 years                   Fractal Analytics3.9(95 Reviews)   \n",
       "7         0 - 2 years                 Jet2 Travel Technologies Pvt. Ltd.   \n",
       "8         0 - 5 years  Chaayos (Sunshine Teahouse Pvt. Ltd.)3.9(159 R...   \n",
       "9         0 - 1 years           AlgoAnalytics Private Ltd.4.0(2 Reviews)   \n",
       "\n",
       "                                        job_location  \\\n",
       "0          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "1                                            Chennai   \n",
       "2                                                  -   \n",
       "3                                                  -   \n",
       "4      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "7                                               Pune   \n",
       "8                                          New Delhi   \n",
       "9                                      Pune( Baner )   \n",
       "\n",
       "                                           job_title  \n",
       "0  Data analytics / Data scientist intern (work f...  \n",
       "1  Senior Data Scientist / Lead (Predictive Analy...  \n",
       "2                                                  -  \n",
       "3                                                  -  \n",
       "4                              Senior Data Scientist  \n",
       "5                                Lead Data Scientist  \n",
       "6                                Lead Data Scientist  \n",
       "7             Data Science- Associate Data Scientist  \n",
       "8              Chaayos is Looking For Data Scientist  \n",
       "9                           Associate Data Scientist  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(4)\n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\n",
    "                 \"company_name\":company_name[0:10],\n",
    "                 \"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "series_name=[]\n",
    "year_of_release=[]\n",
    "series_rating=[]\n",
    "seies_votes=[]\n",
    "run_time=[]\n",
    "\n",
    "#scraping names\n",
    "names=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']\")\n",
    "for i in names:\n",
    "    if i.text is None :\n",
    "        series_name.append(\"--\") \n",
    "    else:\n",
    "        series_name.append(i.text)\n",
    "\n",
    "# scraping year of release        \n",
    "year=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in year:\n",
    "    if i.text is None :\n",
    "        year_of_release.append(\"--\") \n",
    "    else:\n",
    "        year_of_release.append(i.text)     \n",
    "        \n",
    "rating=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']\")  # scrapping rating\n",
    "for i in rating:\n",
    "    if i.text is None :\n",
    "        series_rating.append(\"--\") \n",
    "    else:\n",
    "        series_rating.append(i.text)   \n",
    "        \n",
    "        \n",
    "time=driver.find_elements_by_xpath(\"//span[@class='runtime']\")  # scrapping time\n",
    "for i in time:\n",
    "    if i.text is None :\n",
    "        run_time.append(\"--\") \n",
    "    else:\n",
    "        run_time.append(i.text)\n",
    "\n",
    "genre=driver.find_elements_by_xpath(\"//span[@class='genre']\")  #scrapping genre\n",
    "for i in genre:\n",
    "    if i.text is None :\n",
    "        series_genre.append(\"--\") \n",
    "    else:\n",
    "        series_genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(series_name))\n",
    "print(len(year_of_release))\n",
    "print(len(series_rating))\n",
    "print(len(run_time))\n",
    "print(len(series_genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_name</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>series_rating</th>\n",
       "      <th>run_time</th>\n",
       "      <th>series_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011–2019)</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>9.3</td>\n",
       "      <td>57 min</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016– )</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>8.7</td>\n",
       "      <td>51 min</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010–2022)</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>8.2</td>\n",
       "      <td>44 min</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017–2020)</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>60 min</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014–2020)</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>7.6</td>\n",
       "      <td>43 min</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign (2013–2017)</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events (2017–2019)</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>7.8</td>\n",
       "      <td>50 min</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds (2005–2020)</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>8</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series (2015–2019)</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>7.1</td>\n",
       "      <td>45 min</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>8.6</td>\n",
       "      <td>572 min</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       series_name year_of_release  \\\n",
       "0                   1. Game of Thrones (2011–2019)     (2011–2019)   \n",
       "1                      2. Stranger Things (2016– )        (2016– )   \n",
       "2                  3. The Walking Dead (2010–2022)     (2010–2022)   \n",
       "3                    4. 13 Reasons Why (2017–2020)     (2017–2020)   \n",
       "4                           5. The 100 (2014–2020)     (2014–2020)   \n",
       "..                                             ...             ...   \n",
       "95                           96. Reign (2013–2017)     (2013–2017)   \n",
       "96  97. A Series of Unfortunate Events (2017–2019)     (2017–2019)   \n",
       "97                  98. Criminal Minds (2005–2020)     (2005–2020)   \n",
       "98           99. Scream: The TV Series (2015–2019)     (2015–2019)   \n",
       "99          100. The Haunting of Hill House (2018)          (2018)   \n",
       "\n",
       "   series_rating run_time              series_genre  \n",
       "0            9.3   57 min  Action, Adventure, Drama  \n",
       "1            8.7   51 min    Drama, Fantasy, Horror  \n",
       "2            8.2   44 min   Drama, Horror, Thriller  \n",
       "3            7.6   60 min  Drama, Mystery, Thriller  \n",
       "4            7.6   43 min    Drama, Mystery, Sci-Fi  \n",
       "..           ...      ...                       ...  \n",
       "95           7.5   42 min            Drama, Fantasy  \n",
       "96           7.8   50 min  Adventure, Comedy, Drama  \n",
       "97             8   42 min     Crime, Drama, Mystery  \n",
       "98           7.1   45 min      Comedy, Crime, Drama  \n",
       "99           8.6  572 min    Drama, Horror, Mystery  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe\n",
    "df=pd.DataFrame({\"series_name\":series_name,\n",
    "                 \"year_of_release\":year_of_release,\n",
    "                 \"series_rating\":series_rating,\n",
    "                 \"run_time\":run_time,\n",
    "                 \"series_genre\":series_genre})\n",
    "              \n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape the details of trending repositories on Github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "\n",
    "repository_title=[]\n",
    "repository_description=[]\n",
    "language_used=[]\n",
    "\n",
    "\n",
    "title=driver.find_elements_by_xpath(\"//span[@class='text-normal']\")\n",
    "for i in title:\n",
    "    if i.text is None :\n",
    "        repository_title.append(\"----\") \n",
    "    else:\n",
    "        repository_title.append(i.text)\n",
    "\n",
    "        \n",
    "description=driver.find_elements_by_xpath(\"//p[@class='col-9 color-text-secondary my-1 pr-4']\")\n",
    "for i in description:\n",
    "    if i.text is None:\n",
    "        repository_description.append(\"NaN\") \n",
    "    else:\n",
    "        repository_description.append(i.text)     \n",
    "        \n",
    "language=driver.find_elements_by_xpath(\"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "for i in language:\n",
    "    if i.text is None:\n",
    "        language_used.append(\"NaN\") \n",
    "    else:\n",
    "        language_used.append(i.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repository_title</th>\n",
       "      <th>repository_description</th>\n",
       "      <th>language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programthink /</td>\n",
       "      <td>【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AkashSingh3031 /</td>\n",
       "      <td>This repository contains all the DSA (Data-Str...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CaffeineMC /</td>\n",
       "      <td>A Fabric mod designed to improve frame rates a...</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n8n-io /</td>\n",
       "      <td>Free and open fair-code licensed node based Wo...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebookresearch /</td>\n",
       "      <td>A data augmentations library for audio, image,...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vxunderground /</td>\n",
       "      <td>Collection of malware source code for a variet...</td>\n",
       "      <td>Assembly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abuanwar072 /</td>\n",
       "      <td>Responsive Admin Panel or Dashboard using Flutter</td>\n",
       "      <td>Dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EssayKillerBrain /</td>\n",
       "      <td>基于开源GPT2.0的初代创作型人工智能 | 可扩展、可进化</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>organicmaps /</td>\n",
       "      <td>🍃 Organic Maps is a better fork of MAPS.ME, an...</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rustdesk /</td>\n",
       "      <td>Yet another remote desktop software</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>algorithm-visualizer /</td>\n",
       "      <td>🎆Interactive Online Platform that Visualizes A...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>academic /</td>\n",
       "      <td>📝 An awesome Data Science repository to learn ...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>megaease /</td>\n",
       "      <td>A Cloud Native traffic orchestration system</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TheBobPony /</td>\n",
       "      <td>For the website</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>donnemartin /</td>\n",
       "      <td>Learn how to design large-scale systems. Prep ...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          repository_title                             repository_description  \\\n",
       "0           programthink /                       【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵   \n",
       "1         AkashSingh3031 /  This repository contains all the DSA (Data-Str...   \n",
       "2             CaffeineMC /  A Fabric mod designed to improve frame rates a...   \n",
       "3                 n8n-io /  Free and open fair-code licensed node based Wo...   \n",
       "4       facebookresearch /  A data augmentations library for audio, image,...   \n",
       "5          vxunderground /  Collection of malware source code for a variet...   \n",
       "6            abuanwar072 /  Responsive Admin Panel or Dashboard using Flutter   \n",
       "7       EssayKillerBrain /                     基于开源GPT2.0的初代创作型人工智能 | 可扩展、可进化   \n",
       "8            organicmaps /  🍃 Organic Maps is a better fork of MAPS.ME, an...   \n",
       "9               rustdesk /                Yet another remote desktop software   \n",
       "10  algorithm-visualizer /  🎆Interactive Online Platform that Visualizes A...   \n",
       "11              academic /  📝 An awesome Data Science repository to learn ...   \n",
       "12              megaease /        A Cloud Native traffic orchestration system   \n",
       "13            TheBobPony /                                    For the website   \n",
       "14           donnemartin /  Learn how to design large-scale systems. Prep ...   \n",
       "\n",
       "       language_used  \n",
       "0             Python  \n",
       "1   Jupyter Notebook  \n",
       "2               Java  \n",
       "3         TypeScript  \n",
       "4             Python  \n",
       "5           Assembly  \n",
       "6               Dart  \n",
       "7             Python  \n",
       "8                C++  \n",
       "9               Rust  \n",
       "10        JavaScript  \n",
       "11                Go  \n",
       "12              HTML  \n",
       "13            Python  \n",
       "14            Python  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe\n",
    "df=pd.DataFrame({\"repository_title\":repository_title[0:15],\n",
    "                 \"repository_description\":repository_description[0:15],\n",
    "                 \"language_used\":language_used[0:15]})\n",
    "           \n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.billboard.com/charts/hot-100\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "\n",
    "song_name=[]\n",
    "artist_name=[]\n",
    "last_week_rank=[]\n",
    "peak_rank=[]\n",
    "weeks_on_board=[]\n",
    "\n",
    "\n",
    "song=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in song:\n",
    "    if i.text is None :\n",
    "        song_name.append(\"----\") \n",
    "    else:\n",
    "        song_name.append(i.text)\n",
    "\n",
    "        \n",
    "artist=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in artist:\n",
    "    if i.text is None:\n",
    "        artist_name.append(\"---\") \n",
    "    else:\n",
    "        artist_name.append(i.text)     \n",
    "        \n",
    "last_rank=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in last_rank:\n",
    "    if i.text is None:\n",
    "        last_week_rank.append(\"---\") \n",
    "    else:\n",
    "        last_week_rank.append(i.text)   \n",
    "        \n",
    "        \n",
    "board=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in board:\n",
    "    if i.text is None:\n",
    "        weeks_on_board.append(\"---\") \n",
    "    else:\n",
    "        weeks_on_board.append(i.text)\n",
    "        \n",
    "        \n",
    "peak=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak:\n",
    "    if i.text is None:\n",
    "        peak_rank.append(\"---\") \n",
    "    else:\n",
    "        peak_rank.append(i.text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(song_name))\n",
    "print(len(artist_name))\n",
    "print(len(last_week_rank))\n",
    "print(len(peak_rank))\n",
    "print(len(weeks_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>last_week_rank</th>\n",
       "      <th>peak_rank</th>\n",
       "      <th>weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Things A Man Oughta Know</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Country Again</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Drunk (And I Don't Wanna Go Home)</td>\n",
       "      <td>Elle King &amp; Miranda Lambert</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>If You Want To</td>\n",
       "      <td>Lil Baby &amp; Lil Durk</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeing Green</td>\n",
       "      <td>Nicki Minaj, Drake &amp; Lil Wayne</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            song_name  \\\n",
       "0                              Butter   \n",
       "1                            Good 4 U   \n",
       "2                          Levitating   \n",
       "3                             Peaches   \n",
       "4                 Leave The Door Open   \n",
       "..                                ...   \n",
       "95           Things A Man Oughta Know   \n",
       "96                      Country Again   \n",
       "97  Drunk (And I Don't Wanna Go Home)   \n",
       "98                     If You Want To   \n",
       "99                       Seeing Green   \n",
       "\n",
       "                                       artist_name last_week_rank peak_rank  \\\n",
       "0                                              BTS              1         1   \n",
       "1                                   Olivia Rodrigo              2         1   \n",
       "2                        Dua Lipa Featuring DaBaby              3         2   \n",
       "3   Justin Bieber Featuring Daniel Caesar & Giveon              6         1   \n",
       "4         Silk Sonic (Bruno Mars & Anderson .Paak)              4         1   \n",
       "..                                             ...            ...       ...   \n",
       "95                                   Lainey Wilson             93        93   \n",
       "96                                    Thomas Rhett             89        73   \n",
       "97                     Elle King & Miranda Lambert             92        79   \n",
       "98                             Lil Baby & Lil Durk              -        99   \n",
       "99                  Nicki Minaj, Drake & Lil Wayne             67        12   \n",
       "\n",
       "   weeks_on_board  \n",
       "0               3  \n",
       "1               4  \n",
       "2              36  \n",
       "3              12  \n",
       "4              14  \n",
       "..            ...  \n",
       "95              4  \n",
       "96              6  \n",
       "97              7  \n",
       "98              1  \n",
       "99              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe\n",
    "df=pd.DataFrame({\"song_name\":song_name,\n",
    "                 \"artist_name\":artist_name,\n",
    "                 \"last_week_rank\":last_week_rank,\n",
    "                 \"peak_rank\":peak_rank,\n",
    "                 \"weeks_on_board\":weeks_on_board})\n",
    "                \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape the details team India’s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.bcci.tv/international/fixtures\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "match_title=[]\n",
    "match_series=[]\n",
    "time_of_match=[]\n",
    "match_teams=[]\n",
    "\n",
    "\n",
    "\n",
    "title=driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__format']\")\n",
    "for i in title:\n",
    "    if i.text is None :\n",
    "        match_title.append(\"----\") \n",
    "    else:\n",
    "        match_title.append(i.text)\n",
    "\n",
    "        \n",
    "series=driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "for i in series:\n",
    "    if i.text is None:\n",
    "        match_series.append(\"---\") \n",
    "    else:\n",
    "        match_series.append(i.text)     \n",
    "        \n",
    "time=driver.find_elements_by_xpath(\"//span[@class='fixture__datetime tablet-only']\")\n",
    "for i in time:\n",
    "    if i.text is None:\n",
    "        time_of_match.append(\"---\") \n",
    "    else:\n",
    "        time_of_match.append(i.text)\n",
    "\n",
    "teams=driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "for i in teams:\n",
    "    if i.text is None:\n",
    "        match_teams.append(\"---\") \n",
    "    else:\n",
    "        match_teams.append(i.text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_title</th>\n",
       "      <th>match_series</th>\n",
       "      <th>time_of_match</th>\n",
       "      <th>match_teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST</td>\n",
       "      <td>Final</td>\n",
       "      <td>Friday 18th June 15:00 IST</td>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ODI</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Tuesday 13th July 14:30 IST</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ODI</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Friday 16th July 14:30 IST</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ODI</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Sunday 18th July 14:30 IST</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T20I</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Wednesday 21st July 19:00 IST</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Friday 23rd July 19:00 IST</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T20I</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Sunday 25th July 19:00 IST</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST</td>\n",
       "      <td>1st Test</td>\n",
       "      <td>Wednesday 4th August 15:30 IST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>Thursday 12th August 15:30 IST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Wednesday 25th August 15:30 IST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>Thursday 2nd September 15:30 IST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>Friday 10th September 15:30 IST</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_title match_series                     time_of_match  \\\n",
       "0         TEST        Final        Friday 18th June 15:00 IST   \n",
       "1          ODI      1st ODI       Tuesday 13th July 14:30 IST   \n",
       "2          ODI      2nd ODI        Friday 16th July 14:30 IST   \n",
       "3          ODI      3rd ODI        Sunday 18th July 14:30 IST   \n",
       "4         T20I     1st T20I     Wednesday 21st July 19:00 IST   \n",
       "5         T20I     2nd T20I        Friday 23rd July 19:00 IST   \n",
       "6         T20I     3rd T20I        Sunday 25th July 19:00 IST   \n",
       "7         TEST     1st Test    Wednesday 4th August 15:30 IST   \n",
       "8         TEST     2nd Test    Thursday 12th August 15:30 IST   \n",
       "9         TEST     3rd Test   Wednesday 25th August 15:30 IST   \n",
       "10        TEST     4th Test  Thursday 2nd September 15:30 IST   \n",
       "11        TEST     5th Test   Friday 10th September 15:30 IST   \n",
       "\n",
       "                    match_teams  \n",
       "0   ICC WORLD TEST CHAMPIONSHIP  \n",
       "1        SRI LANKA V INDIA 2021  \n",
       "2        SRI LANKA V INDIA 2021  \n",
       "3        SRI LANKA V INDIA 2021  \n",
       "4        SRI LANKA V INDIA 2021  \n",
       "5        SRI LANKA V INDIA 2021  \n",
       "6        SRI LANKA V INDIA 2021  \n",
       "7          ENGLAND V INDIA 2021  \n",
       "8          ENGLAND V INDIA 2021  \n",
       "9          ENGLAND V INDIA 2021  \n",
       "10         ENGLAND V INDIA 2021  \n",
       "11         ENGLAND V INDIA 2021  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe\n",
    "df=pd.DataFrame({\"match_title\":match_title,\n",
    "                 \"match_series\":match_series,\n",
    "                 \"time_of_match\":time_of_match,\n",
    "                 \"match_teams\":match_teams})\n",
    "                 \n",
    "                \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape the rank of State-wise GDP of India from statisticstime.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"http://statisticstimes.com/economy/india/indian-states-gdp.php\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "rank_of_state=[]\n",
    "name_of_state=[]\n",
    "\n",
    "rank=driver.find_elements_by_xpath(\"//td[@class='data1']\")\n",
    "for i in rank:\n",
    "    if i.text is None :\n",
    "        rank_of_state.append(\"----\") \n",
    "    else:\n",
    "        rank_of_state.append(i.text)\n",
    "\n",
    "        \n",
    "state=driver.find_elements_by_xpath(\"//td[@class='name']\")\n",
    "for i in state:\n",
    "    if i.text is None:\n",
    "        name_of_state.append(\"---\") \n",
    "    else:\n",
    "        name_of_state.append(i.text)     \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(rank_of_state))\n",
    "print(len(name_of_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_of_state</th>\n",
       "      <th>name_of_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sikkim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Haryana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>30</td>\n",
       "      <td>Jharkhand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>31</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>32</td>\n",
       "      <td>Bihar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td></td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_of_state              name_of_state\n",
       "0              1                        Goa\n",
       "1              2                     Sikkim\n",
       "2              3                      Delhi\n",
       "3              4                 Chandigarh\n",
       "4              5                    Haryana\n",
       "..           ...                        ...\n",
       "63            30                  Jharkhand\n",
       "64            31              Uttar Pradesh\n",
       "65            32                      Bihar\n",
       "66            33  Andaman & Nicobar Islands\n",
       "67                                    India\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe\n",
    "df=pd.DataFrame({\"rank_of_state\":rank_of_state,\n",
    "                 \"name_of_state\":name_of_state})\n",
    "                                 \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.guru99.com/selenium-tutorial.html\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls \n",
    "selenium_urls = []\n",
    "urls = driver.find_elements_by_xpath(\"//td[@class='responsivetable']\")\n",
    "for url in urls:\n",
    "    selenium_urls.append(url.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selenium_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
